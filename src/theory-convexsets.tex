\documentclass{article}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proof}{Proof}[section]

\pagestyle{fancy}
\fancyhf{}
\rhead{DanDoge}
\lhead{Notes on convex sets}
\rfoot{Page \thepage}
\cfoot{latest version: 2018/02/08}

\title{Notes on convex sets}
\date{2018-01-25}
\author{DanDoge}

\begin{document}

\section{Affine and convex sets}
  \subsection{lines and line segments}
    \paragraph{} \textit{line} is points of the form $y = \theta x_1 + (1 - \theta) x_2$ where $\theta \in R$, and $x_1 \neq x_2$.
    \paragraph{} \textit{line segement} corresponds to points where parameter $\theta$ is between 0 and 1.
  \subsection{affine sets}
    \paragraph{} a set is \textit{affine} iff for any $x_1, x_2 \in C$ and $\theta \in R$, we have $\theta x_1 + (1 - \theta) x_2 \in C$. This idea can be generalized to more than two points. That is to say, a affine set contains every affine combination of its points: $C$ is an affine set, $x_1, x_2,...,x_k \in C$, and $\theta_1 +...+ \theta_k = 1$, then the point $\theta_1 x_1 + ... + \theta_k x_k$ also belongs to $C$.
    \paragraph{} if $C$ is an affine set and $x_0 \in C$, then the set $V = C - x_0 = \{x\ -\ x_0\ |\ x\ \in C \}$ is a subspace. thus any affine set could be expressed as a subspace plus an offset, and the subspace doesnot depend on the choice of $x_0$.
    \paragraph{} the set of all affine combination of points in some set $C$ is called the \textit{affine hull} of $C$:
    \begin{equation}
      \mathbf{affC} = \{\theta_1 x_1 + ... + \theta_k x_k\ |\  x_1, x_2,...,x_k \in C,\ \theta_1 +...+ \theta_k = 1\}.
    \end{equation}
  \subsection{affine dimension and relative interior}
    \paragraph{} we define the $\textit{affine dimension}$ of a set $C$ as the dimension of its affine hull. if the affine dimension of $C$ is less than n, then the set lies in a affine set $\mathbf{aff C} \neq \mathbf{R}^n$. we define $\textit{relative interior}$ if the set $C$, denoted $\mathbf{relintC}$, as its interior relative to $\mathbf{affC}$:
    \begin{equation}
      \mathbf{relintC} = \{ x \in C\  |\  B(x, r) \cap \textit{aff}C \subset C \ for\ some\ r > 0\}
    \end{equation}
    where $B(x, r) = \{y | \left \| y - x \right \| \leq r\}$. we can then define the \textit{ralative boundary} of a set $C$ as $\mathbf{cl}C$ \\ $\mathbf{relint}C$, where $\mathbf{cl}C$ is the closure of $C$.
  \subsection{convex sets}
    \paragraph{} a seet $C$ is \textit{convex} if the line segment between any two points in $C$ lies in $C$. roughly speaking, a set is convex if every point in the set can be seen by every other point.
    \paragraph{} we call a point of the form $\theta_1 x_1 + ... + \theta_k x_k$, where $\theta_1 +...+ \theta_k = 1$, and $\theta_i \ge 0$, a \textit{convex combination} of the points $x_1,..., x_k$. a set is convex iff it contains every convex combination of its points. the \textit{convex hull} of a set $C$, denoted $\mathbf{conv} C$, is the set of all convex combinations of the points in $C$. the idea of a convex combination can be generalized to include infinite sums, integrals, and probability distributions. suppose $\theta_i$ satisfy
    \begin{equation}
      \theta_i \ge 0, i = 1,2,...,\quad \sum_{i = 1}^{\infty} \theta_i = 1,
    \end{equation}
    and $x_1, x_2,... \in C$, where $C \subset \mathbf{R}^n$ is convex, then
    \begin{equation}
      \sum_{i = 1}^{\infty} \theta_i x_i \in C,
    \end{equation}
    if the series converges. more generally, suppose $C \subset \mathbf{R}^n$ is convex and $x$ is a random vector with $x \in C$ with probability one, then $\mathbf{E}x \in C$.
  \subsection{cones}
    \paragraph{} a set is called a \textit{cone}, or \textit{nonnegative homogeneous}, if for every $x \in C$ and $\theta \ge 0$ we have $\theta x \in C$. a point of the form $\theta_1 x_1 + ... + \theta_k x_k$ with $\theta_i \ge 0$ is called \textit{conic combination} or a \textit{nonnegative linear combination} of $x_i$. a set $C$ is a convex cone iff it contains all conic combinations of its elements. this idea could also be generalized to infinite sums and integrals. the \textit{conic hull} of a set $C$ is the set of all conic combinations of points in $C$.

\section{some important examples}
  \subsection{hyperplanes and halfspaces}
    \paragraph{} a \textit{hyperplane} is a set of the form
    \begin{equation}
      \{x\ |\ a^Tx = b\},
    \end{equation}
    where $a \in \mathbf{R}^n,\ a \neq 0$, and $b \in \mathbf{R}$. this repersentation can inturn be expressed as
    \begin{equation}
      \{x\ |\ a^T(x - x_0) = 0\} = x_0 + a^{\perp},
    \end{equation}
    where $a^{\perp}$ denotes the orthogonal complement of $a$, $i.e.$, the set of all vectors orthogonal to it.
    \paragraph{} a hyperplane divides $\mathbf{R}^n$ into two \textit{halfspaces}, which a set of the form
    \begin{equation}
      \{x\ |\ a^Tx \leq b\},
    \end{equation}
    where $a \neq 0$
  \subsection{euclidean balls and ellipsoids}
    \paragraph{} a \textit{(euclidean) ball} in $\mathbf{R}^n$ has the form
    \begin{equation}
      B(x_c, r) = \{x\ |\ \| x \ - \ x_c \| \leq \ r\} = \{x\ |\ (x\ -\ x_c)^T(x\ -\ x_c) \leq \ r^2\},
    \end{equation}
    where $r\ \ge 0$, and the vector $x_c$ is the \textit{center} of the ball and the saclar $r$ is its $radius$. another common repersentation for the euclidean ball is
    \begin{equation}
      B(x_c, r) = \{x_c\ +\ ru\ |\ \|u\|\ \leq\ 1\},
    \end{equation}
    a euclidean ball is a convex set (use the homogeneity and triangle inequality for $\|\cdot\|_2$)
    \paragraph{} a related family of convex sets is the \textit{ellipsoids}, which have the form
    \begin{equation}
      \mathcal{E}\ =\ \{x\ |\ (x - x_c)^TP^{-1}(x - x_c)\leq 1\},
    \end{equation}
    where $P$ is symmetric and positive definite. the vector $x_c \in \mathbf{R}^n$ is the \textit{center} of the ellipsoid. the matrix $P$ determines how far the ellipsoid extends in every direction from $x_c$ by the square root of its eigenvalues. another common repersentation of an ellipsoid is
    \begin{equation}
      \mathcal{E}\ =\ \{x_c + Au\ |\ \|u\|_2\ \leq\ 1\},
    \end{equation}
    where $A$ is the square and nonsingular, in fact, $A\ =\ P^{1/2}$. when the matrix $A$ is symmetric positive semidefinite but not singular, the set is called a \textit{degenerate ellipsoid}, its affine dimension is equal to the rank of $A$, and it is also convex.
  \subsection{norm balls and norm cones}
    \paragraph{} a \textit{norm ball} of radius $r$ and center $x_c$ given by $\{x\ |\ \|x - x_c\|\ \leq\ r\}$, is convex. the \textit{norm cone} associated with the norm $\|\cdot\|$ is the set
    \begin{equation}
      C\ =\ \{(x,t)\ |\ \|x\|\ \leq\ t\}\ \subset\ \mathbf{R}^{n + 1}.
    \end{equation}
    it is also a convex set, as the name suggests.
  \subsection{polyhera}
    \paragraph{} a \textit{polyheron} is defined as the solution set of a finite number of linear equalities and inequalities:
    \begin{equation}
      \mathcal{P} = \{x\ |\ a_j^Tx \leq b_j,\ j = 1,...,m,\ c_j^Tx = d_j,\ j = 1,...,p\}.
    \end{equation}
    it will be convenient to use the compact notation
    \begin{equation}
      \mathcal{P} = \{x\ |\ Ax\preceq b,\ Cx = d\},
    \end{equation}
    where
    \begin{equation}
      A =
      \begin{bmatrix}
        a_1^T \\
        \vdots \\
        a_m^T
      \end{bmatrix}
      ,\quad
      C =
      \begin{bmatrix}
        c_1^T \\
        \vdots \\
        c_p^T
      \end{bmatrix}
      ,
    \end{equation}
    and the symbol $\preceq$ denotes \textit{vector inequality} or \textit{componentwise inequality} in $\mathbf{R}^m$.
    \subsubsection{simplexes}
      \paragraph{} suppose the $k + 1$ points $v+0, ..., v_k\ \in\ \mathbf{R}^n$ are \textit{affinely independent}, then the simplex determined by then is given by
      \begin{equation}
        C = \mathbf{conv}\{v_0,...,v_k\} = \{\theta_0v_0 +\dots+\theta_kv_k\ |\ \theta \succeq 0,\ \mathbf{1}^T\theta = 1\},
      \end{equation}
      where $\mathbf{1}$ denotes the vector with all entries one. to show the simplex is a polyheron, we define $y = (\theta_1,...,\theta_k)$ and
      \begin{equation}
        B = [v_1 - v_0\ \dots\ v_k - v_0]\ \in\ \mathbf{R}^{n\*k},
      \end{equation}
      we can say that $x \in C$ iff
      \begin{equation}
        x = v_0 + By
      \end{equation}
      we note that affine independence of the points implies that the matrix $B$ has rank $k$, therefore there exists a nonsingular matrix $A = (A_1,A_2)\in\mathbf{R}^{n\*n}$ s.t.
      \begin{equation}
        AB =
        \begin{bmatrix}
          A_1 \\
          A_2
        \end{bmatrix}
        B =
        \begin{bmatrix}
          I \\
          0
        \end{bmatrix}.
      \end{equation}
      in other words, we have $x \in C$ iff
      \begin{equation}
        A_2x = A_2v_0,\quad A_1x \succeq A_1v_0,\quad \mathbf{1}^TA_1x \leq 1 + \mathbf{1}^TA_1v_0.
      \end{equation}
    \subsubsection{convex hull description of polyhedra}
      \paragraph{} the convex hull of a finite set $\{v_1,...,v_k\}$ is
      \begin{equation}
        \mathbf{conv}\{v_1,...,v_k\} = \{\theta_1v_1+...,\theta_kv_k\ |\ \theta \succeq 0,\ \mathbf{1}^T\theta = 1\}.
      \end{equation}
      a generalization of this convex hull description is
      \begin{equation}
        \{\theta_1v_1+...,\theta_kv_k\ |\ \theta_1+\dots+\theta_m\ = 1,\ \theta_i \ge 0,\ i = 1,...,k\},
      \end{equation}
      this defines a polyheron, and conversely, every polyheron can be repersented in this form.
  \subsection{the positive semidefinite cone}
    \paragraph{} we use the notation $\mathbf{S}^n\ \mathbf{S}_+^n\ \mathbf{S}_{++}^n$ to be analogous to $\mathbf{R}_+\ \mathbf{R}_{++}$, then the set $\mathbf{S}_+^n$ is a convex cone.
\section{operations that preserve convexity}
  \subsection{intersection}
    \paragraph{} convexity is preserved under intersection: if $S_\alpha$ is convex for every $\alpha \in \mathcal{A}$, then $\cap_{\alpha \in \mathcal{A}} S_\alpha$ is convex.
  \subsection{affine functions}
    \paragraph{} suppose $S \subset \mathbf{R}^n$ is convex and $f : \mathbf{R}^n \to \mathbf{R}^m$ is an affine function. then the image of $S$ under $f$,
    \begin{equation}
      f(S) = \{f(x)\ |\ x \in S\},
    \end{equation}
    is convex. similarly, the \textit{inverse image} if $S$ under $f$ in convex. two simple examples aer \textit{scaling} and \textit{translation}, \textit{i.e.} $\alpha S$ and $S + \alpha$ are convex. the \textit{projection} of a convex set onto some of its coordinates is convex. the \textit{sum} of two sets $S_1 + S_2$ is convex, if $S_1$ and $S_2$ are convex. we can also define the \textit{partial sum} of $S_1, S_2 \in \mathbf{R}^n \* \mathbf{R}^m$ as
    \begin{equation}
      S = \{(x, y_1 + y_2)\ |\ (x, y_1) \in S_1,\ (x, y_2) \in S_2\},
    \end{equation}
    where $x \in \mathbf{R}^n$ and $y_i \in \mathbf{R}^m$. partial sums of convex sets are convex.
  \subsection{linear-fractional and perspective functions}
    \subsubsection{the perspective function}
      \paragraph{} we define \textit{perspective function} $P : \mathbf{R}^{n + 1} \to \mathbf{R}^{n}$, as $P(z, t) = z / t$, which normalizes vectors so the last component is one, and drop the last component. if $C \subset \mathbf{dom} P$ is convex then its image
      \begin{equation}
        P(C) = \{P(x)\ |\ x \in C\}
      \end{equation}
      is convex. the imverse image of a convex set under the perspective function is also convex.
    \subsubsection{linear-fractional functions}
      \paragraph{} a \textit{linear-fractional function} is formed by composing the perspective function with an affine function. suppose $g : \mathbf{R}^n \to \mathbf{R}^{m + 1}$ is affine $i.e.$,
      \begin{equation}
        g(x) =
        \begin{bmatrix}
          A \\
          c^T
        \end{bmatrix}
        x +
        \begin{bmatrix}
          b \\
          d
        \end{bmatrix},
      \end{equation}
      the function $f: \mathbf{R}^n \to \mathbf{R}^m$ given by $f = P(g)$, $i.e.$,
      \begin{equation}
        f(x) = (Ax + b) / (c^Tx + d),\quad \mathbf{dom} f = {x\ |\ c^Tx + d > 0},
      \end{equation}
      is called \textit{linear-fractional} (or \textit{projective}) function. like the perspective function, linear-fractional functions preserve convexity. if we define $mathcal{P}(z) = \{t(z, 1)\ |\ t > 0\}$ in $\mathbf{R}^{n + 1}$, and
      \begin{equation}
        Q =
        \begin{bmatrix}
          A   & b  \\
          c^T & d
        \end{bmatrix}
        \in \mathbf{R}^{(m + 1) * (n + 1)}
      \end{equation}
      then the linear-fractional function can be expressed as
      \begin{equation}
        f(x) = \mathcal{P}^{-1}(Q\mathcal{P}(x)).
      \end{equation}
\section{generalized inequalities}
  \subsection{proper cones and generalized inequalities}
    \paragraph{} a cone $K \subseteq \mathbf{R}^n$ is called a \textit{proper cone} if it satisfies the following:
    \begin{itemize}
      \item $K$ is convex.
      \item $K$ is closed.
      \item $K$ is \textit{solid}, which means it has nonempty interior.
      \item $K$ is \textit{pointed}, which means that it contains no line.
    \end{itemize}
    we associate with the proper cone $K$ the partial ordering on $\mathbf{R}^n$ defined by
    \begin{equation}
      x \preceq_K y \iff y - x \in K.
    \end{equation}
    similarly, wedefine an associated strict partial ordering by
    \begin{equation}
      x \prec_K y \iff y - x \in \mathbf{int} K.
    \end{equation}
    when $K = \mathbf{R}_+$, the partial ordering $\preceq_K$ is the usual ordering $\leq$ on $\mathbf{R}$.
    \subsubsection{properties of generalized inequalities}
      \paragraph{} transitive, reflexive, antisymmetric, preserved under addition, nonnegative scaling, limits.
  \subsection{minimum and minimal elements}
    \paragraph{} this part is totally the same as \textit{set and graph theory} in PKU.
\section{separaing and supporting hyperplanes}
  \subsection{separaing hyperplane theorem}
    \paragraph{} suppose $C$ and $D$ are nonempty disjoint convex sets, then there exists $a \neq 0$ and $b$ such that $a^Tx \leq b$ for all $x \in C$ and $a^Tx \ge b$ for all $x \in D$.
    \subsubsection{proof of separaing hyperplane theorem}
      we assume the (euclidean) \textit{distance} between $C$ and $D$, defined as
      \begin{equation}
        \mathbf{dist}(C, D) = inf\{\|u - v\|_2 \ |\ u \in C,\ v \in D\},
      \end{equation}
      and there exists points $c \in C$ and $d \in D$ that achieve the minimum distance, define $a = d - c,\quad b = \frac{\|d\|_2^2 - \|c\|_2^2}{2}$, we will show that the affine function
      \begin{equation}
        f(x) = a^T x - b = (d - c)^T(x - (1/2)(c + d))
      \end{equation}
      is nonpositive on $C$ and nonnegative on $D$, $i.e.$, this hyperplane separates $C$ and $D$.
    \subsubsection{strict separation}
      \paragraph{} the separating hyperplane we constructed above satisfies the stronger condition that $a^Tx \le b$ for all $x \in C$ and $a^Tx \ge b$ for all $x \in D$, this is called \textit{strict separation}.
    \subsubsection{converse separaing hyperplane theorem}
      \paragraph{} is not true, that existence of a separaing hyperplane implies that $C$ and $D$ do not intersect, however, if we suppose at least one of these two sets is open, then this is true.
  \subsection{supporting hyperplanes}
    \paragraph{} suppose $C \in \mathbf{R}^n$, adn $x_0$ is a point in its boundary $\mathbf{bd}C$, if $a \neq 0$ satisfies $a^Tx \leq a^Tx_0$ for all $x \in C$, then the hyperplane $\{x\ |\ a^Tx = a^Tx_0\}$ is called a \textit{supporting hyperplane} to $C$ at the point $x_0$. a basic result, called the \textit{supporting hyperplane theorem}, states that for any nonempty convex sets $C$, and any $x_0 \in \mathbf{bd} C $, there exists a supporting hyperplane to $C$ at $x_0$.
\section{dual cones and generalized inequalities}
  \subsection{dual cones}
    \paragraph{} let $K$ be a cone, the sec
    \begin{equation}
      K^* = \{y\ |\ x^Ty \geq 0\ for\ all\ x \in K\}
    \end{equation}
    is called the \textit{dual cone} of $K$. $K^*$ is a cone, and is always convex, even the orginal cone $K$ is not.
    \paragraph{} dual cone satisfy several properties, such as:
    \begin{itemize}
      \item $K^*$ is closed adn convex
      \item $K_1 \subseteq K_2$ implies $K_2^* \subseteq K_1^*$
      \item if $K$ has nonempty interior, then $K^*$ is pointed
      \item $K^{**}$ is the closure of the convex hull of $K$
    \end{itemize}
  \subsection{dual generalized inequalities}
    \paragraph{} suppose that the convex cone $K$ is proper, then it induces a generalized inequality $\preceq_K$, and the \textit{dual} of the generalized inequality $\preceq_{K^*}$
    \paragraph{} some important properties relating a generalized inequality and its dual are:
    \begin{itemize}
      \item $x \preceq_K y$ iff $\lambda^Tx \leq \lambda^Ty$ for all $\lambda \succeq_{K^*} 0$
      \item $x \prec_K y$ iff $\lambda^Tx \le \lambda^Ty$ for all $\lambda \succeq_{K^*} 0$, $\lambda \neq 0$.
    \end{itemize}
  \subsection{minimum adn minimal elements via dual inequalities}
    \subsubsection{dual characterization of minimum element}
      \paragraph{} the \textit{minimum} element: $x$ is the minimum element of $S$, with respect to the generalized inequality $\preceq_K$, iff for all $\lambda \succ_{K^*}$ 0, $x$ is the unique minmizer of $\lambda^Tz$ over $z \in S$. this means that for any $\lambda \succ_{K^*}$ 0, the hyperplane
      \begin{equation}
        \{z\ |\ \lambda^T(z - x) = 0\}
      \end{equation}
      is a strict supporting hyperplane to $S$ at $x$
    \subsubsection{dual characterization of minimal elements}
      \paragraph{} if $\lambda \succ_{K^*}$ 0 and $x$ minimizes $\lambda^Tz$ over $z \in S$, then $x$ is minimal, the converse is in general false, except that $S$ is convex.
\end{document}
